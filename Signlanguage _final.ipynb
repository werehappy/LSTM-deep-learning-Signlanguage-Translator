{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a38bd8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "import mediapipe as mp\n",
    "from xlrd import open_workbook\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline \n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score # Accuracy metrics "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d59a13",
   "metadata": {},
   "source": [
    "# Functions for Mediapipe and Extracting Keypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b9be98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_holistic = mp.solutions.holistic # Holistic model\n",
    "mp_drawing = mp.solutions.drawing_utils # Drawing utilities\n",
    "\n",
    "def mediapipe_detection(image, model):\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) # COLOR CONVERSION BGR 2 RGB\n",
    "    image.flags.writeable = False                  # Image is no longer writeable\n",
    "    results = model.process(image)                 # Make prediction\n",
    "    image.flags.writeable = True                   # Image is now writeable \n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR) # COLOR COVERSION RGB 2 BGR\n",
    "    return image, results\n",
    "\n",
    "def draw_landmarks(image, results):\n",
    "    mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACEMESH_TESSELATION) # Draw face connections\n",
    "    mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS) # Draw pose connections\n",
    "    mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS) # Draw left hand connections\n",
    "    mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS) # Draw right hand connections\n",
    "    \n",
    "def draw_styled_landmarks(image, results):\n",
    "    # Draw face connections\n",
    "    mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACEMESH_TESSELATION, \n",
    "                             mp_drawing.DrawingSpec(color=(80,110,10), thickness=1, circle_radius=1), \n",
    "                             mp_drawing.DrawingSpec(color=(80,256,121), thickness=1, circle_radius=1)\n",
    "                             ) \n",
    "    # Draw pose connections\n",
    "    mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS,\n",
    "                             mp_drawing.DrawingSpec(color=(80,22,10), thickness=2, circle_radius=4), \n",
    "                             mp_drawing.DrawingSpec(color=(80,44,121), thickness=2, circle_radius=2)\n",
    "                             ) \n",
    "    # Draw left hand connections\n",
    "    mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                             mp_drawing.DrawingSpec(color=(121,22,76), thickness=2, circle_radius=4), \n",
    "                             mp_drawing.DrawingSpec(color=(121,44,250), thickness=2, circle_radius=2)\n",
    "                             ) \n",
    "    # Draw right hand connections  \n",
    "    mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                             mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=4), \n",
    "                             mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2)\n",
    "                             ) \n",
    "    \n",
    "def extract_keypoints(results):\n",
    "    pose = np.array([[res.x, res.y, res.z, res.visibility] for res in results.pose_landmarks.landmark]).flatten() if results.pose_landmarks else np.zeros(33*4)\n",
    "    face = np.array([[res.x, res.y, res.z] for res in results.face_landmarks.landmark]).flatten() if results.face_landmarks else np.zeros(468*3)\n",
    "    lh = np.array([[res.x, res.y, res.z] for res in results.left_hand_landmarks.landmark]).flatten() if results.left_hand_landmarks else np.zeros(21*3)\n",
    "    rh = np.array([[res.x, res.y, res.z] for res in results.right_hand_landmarks.landmark]).flatten() if results.right_hand_landmarks else np.zeros(21*3)\n",
    "    return np.concatenate([pose, face, lh, rh])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a7eaf89",
   "metadata": {},
   "source": [
    "# Extract Keypoint Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "43902e2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130\n",
      "địa chỉ\n",
      "Done\n",
      "130\n",
      "địa chỉ\n",
      "Done\n",
      "130\n",
      "địa chỉ\n",
      "Done\n",
      "130\n",
      "địa chỉ\n",
      "Done\n",
      "130\n",
      "địa chỉ\n",
      "Done\n",
      "130\n",
      "địa chỉ\n",
      "Done\n",
      "130\n",
      "địa chỉ\n",
      "Done\n",
      "130\n",
      "địa chỉ\n",
      "Done\n",
      "130\n",
      "địa chỉ\n",
      "Done\n",
      "130\n",
      "địa chỉ\n",
      "Done\n",
      "130\n",
      "địa chỉ\n",
      "Done\n",
      "130\n",
      "địa chỉ\n",
      "Done\n",
      "130\n",
      "địa chỉ\n",
      "Done\n",
      "130\n",
      "địa chỉ\n",
      "Done\n",
      "130\n",
      "địa chỉ\n",
      "Done\n",
      "130\n",
      "địa chỉ\n",
      "Done\n",
      "130\n",
      "địa chỉ\n",
      "Done\n",
      "130\n",
      "địa chỉ\n",
      "Done\n",
      "130\n",
      "địa chỉ\n",
      "Done\n",
      "130\n",
      "địa chỉ\n",
      "Done\n",
      "130\n",
      "địa chỉ\n",
      "Done\n",
      "130\n",
      "địa chỉ\n",
      "Done\n",
      "130\n",
      "địa chỉ\n",
      "Done\n",
      "130\n",
      "địa chỉ\n",
      "Done\n",
      "130\n",
      "địa chỉ\n",
      "Done\n",
      "130\n",
      "địa chỉ\n",
      "Done\n",
      "130\n",
      "địa chỉ\n",
      "Done\n",
      "130\n",
      "địa chỉ\n",
      "Done\n",
      "130\n",
      "địa chỉ\n",
      "Done\n",
      "130\n",
      "địa chỉ\n",
      "Done\n",
      "147\n",
      "Tỉnh\n",
      "Done\n",
      "147\n",
      "Tỉnh\n",
      "Done\n",
      "147\n",
      "Tỉnh\n",
      "Done\n",
      "147\n",
      "Tỉnh\n",
      "Done\n",
      "147\n",
      "Tỉnh\n",
      "Done\n",
      "147\n",
      "Tỉnh\n",
      "Done\n",
      "147\n",
      "Tỉnh\n",
      "Done\n",
      "147\n",
      "Tỉnh\n",
      "Done\n",
      "147\n",
      "Tỉnh\n",
      "Done\n",
      "147\n",
      "Tỉnh\n",
      "Done\n",
      "147\n",
      "Tỉnh\n",
      "Done\n",
      "147\n",
      "Tỉnh\n",
      "Done\n",
      "147\n",
      "Tỉnh\n",
      "Done\n",
      "147\n",
      "Tỉnh\n",
      "Done\n",
      "147\n",
      "Tỉnh\n",
      "Done\n",
      "147\n",
      "Tỉnh\n",
      "Done\n",
      "147\n",
      "Tỉnh\n",
      "Done\n",
      "147\n",
      "Tỉnh\n",
      "Done\n",
      "147\n",
      "Tỉnh\n",
      "Done\n",
      "147\n",
      "Tỉnh\n",
      "Done\n",
      "147\n",
      "Tỉnh\n",
      "Done\n",
      "147\n",
      "Tỉnh\n",
      "Done\n",
      "147\n",
      "Tỉnh\n",
      "Done\n",
      "147\n",
      "Tỉnh\n",
      "Done\n",
      "147\n",
      "Tỉnh\n",
      "Done\n",
      "147\n",
      "Tỉnh\n",
      "Done\n",
      "147\n",
      "Tỉnh\n",
      "Done\n",
      "147\n",
      "Tỉnh\n",
      "Done\n",
      "147\n",
      "Tỉnh\n",
      "Done\n",
      "147\n",
      "Tỉnh\n",
      "Done\n",
      "125\n",
      "Tiếp Tân\n",
      "Done\n",
      "125\n",
      "Tiếp Tân\n",
      "Done\n",
      "125\n",
      "Tiếp Tân\n",
      "Done\n",
      "125\n",
      "Tiếp Tân\n",
      "Done\n",
      "125\n",
      "Tiếp Tân\n",
      "Done\n",
      "125\n",
      "Tiếp Tân\n",
      "Done\n",
      "125\n",
      "Tiếp Tân\n",
      "Done\n",
      "125\n",
      "Tiếp Tân\n",
      "Done\n",
      "125\n",
      "Tiếp Tân\n",
      "Done\n",
      "125\n",
      "Tiếp Tân\n",
      "Done\n",
      "125\n",
      "Tiếp Tân\n",
      "Done\n",
      "125\n",
      "Tiếp Tân\n",
      "Done\n",
      "125\n",
      "Tiếp Tân\n",
      "Done\n",
      "125\n",
      "Tiếp Tân\n",
      "Done\n",
      "125\n",
      "Tiếp Tân\n",
      "Done\n",
      "125\n",
      "Tiếp Tân\n",
      "Done\n",
      "125\n",
      "Tiếp Tân\n",
      "Done\n",
      "125\n",
      "Tiếp Tân\n",
      "Done\n",
      "125\n",
      "Tiếp Tân\n",
      "Done\n",
      "125\n",
      "Tiếp Tân\n",
      "Done\n",
      "125\n",
      "Tiếp Tân\n",
      "Done\n",
      "125\n",
      "Tiếp Tân\n",
      "Done\n",
      "125\n",
      "Tiếp Tân\n",
      "Done\n",
      "125\n",
      "Tiếp Tân\n",
      "Done\n",
      "125\n",
      "Tiếp Tân\n",
      "Done\n",
      "125\n",
      "Tiếp Tân\n",
      "Done\n",
      "125\n",
      "Tiếp Tân\n",
      "Done\n",
      "125\n",
      "Tiếp Tân\n",
      "Done\n",
      "125\n",
      "Tiếp Tân\n",
      "Done\n",
      "125\n",
      "Tiếp Tân\n",
      "Done\n",
      "125\n",
      "nhân viên\n",
      "Done\n",
      "125\n",
      "nhân viên\n",
      "Done\n",
      "125\n",
      "nhân viên\n",
      "Done\n",
      "125\n",
      "nhân viên\n",
      "Done\n",
      "125\n",
      "nhân viên\n",
      "Done\n",
      "125\n",
      "nhân viên\n",
      "Done\n",
      "125\n",
      "nhân viên\n",
      "Done\n",
      "125\n",
      "nhân viên\n",
      "Done\n",
      "125\n",
      "nhân viên\n",
      "Done\n",
      "125\n",
      "nhân viên\n",
      "Done\n",
      "125\n",
      "nhân viên\n",
      "Done\n",
      "125\n",
      "nhân viên\n",
      "Done\n",
      "125\n",
      "nhân viên\n",
      "Done\n",
      "125\n",
      "nhân viên\n",
      "Done\n",
      "125\n",
      "nhân viên\n",
      "Done\n",
      "125\n",
      "nhân viên\n",
      "Done\n",
      "125\n",
      "nhân viên\n",
      "Done\n",
      "125\n",
      "nhân viên\n",
      "Done\n",
      "125\n",
      "nhân viên\n",
      "Done\n",
      "125\n",
      "nhân viên\n",
      "Done\n",
      "125\n",
      "nhân viên\n",
      "Done\n",
      "125\n",
      "nhân viên\n",
      "Done\n",
      "125\n",
      "nhân viên\n",
      "Done\n",
      "125\n",
      "nhân viên\n",
      "Done\n",
      "125\n",
      "nhân viên\n",
      "Done\n",
      "125\n",
      "nhân viên\n",
      "Done\n",
      "125\n",
      "nhân viên\n",
      "Done\n",
      "125\n",
      "nhân viên\n",
      "Done\n",
      "125\n",
      "nhân viên\n",
      "Done\n",
      "125\n",
      "nhân viên\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "wb = open_workbook(r'F:\\Signlanguage\\Jupyter\\DichNNKH\\VideoFileTranslatorList_3_checked_test_2words.xls')\n",
    "sheet = wb.sheet_by_index(0)\n",
    "sheet.cell_value(0, 0)\n",
    "column_index = 0\n",
    "column = sheet.cell_value(0, column_index)\n",
    "\n",
    "#n = 0\n",
    "\n",
    "#Test_Arr = np.array(['A', 'B', 'C', 'D'])\n",
    "\n",
    "# Path for exported data, numpy arrays\n",
    "DATA_PATH = os.path.join('MP_Data') \n",
    "\n",
    "for row in range(3, sheet.nrows):\n",
    "    \n",
    "    Vid_Link = sheet.cell_value(row, column_index + 3)\n",
    "    Letter = sheet.cell_value(row, column_index + 5)\n",
    "    \n",
    "    File_No = str(sheet.cell_value(row, column_index))\n",
    "    #Test = str(Test)\n",
    "    \n",
    "#     disallowed_characters = \".?><\"\n",
    "#     for character in disallowed_characters:\n",
    "#         Letter = Letter.replace(character, \"\")\n",
    "\n",
    "    # One video worth of data\n",
    "    no_sequences = 30\n",
    "\n",
    "    for sequence in range(no_sequences): #Loop through Videos\n",
    "            \n",
    "        npy_path = os.path.join(DATA_PATH, Letter, str(sequence))\n",
    "        os.makedirs(npy_path)\n",
    "\n",
    "        cap = cv2.VideoCapture(Vid_Link)\n",
    "\n",
    "        # Set mediapipe model \n",
    "        with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "\n",
    "\n",
    "            Frame_length = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "            print(Frame_length)\n",
    "            print(Letter)\n",
    "\n",
    "            # Loop through video length aka sequence length\n",
    "            for frame_num in range(30):\n",
    "\n",
    "                # Read feed\n",
    "                ret, frame = cap.read()\n",
    "                \n",
    "\n",
    "                # Make detections\n",
    "                image, results = mediapipe_detection(frame, holistic)\n",
    "\n",
    "                # NEW Export keypoints\n",
    "                keypoints = extract_keypoints(results)\n",
    "                \n",
    "\n",
    "                #npy_path = os.path.join(DATA_PATH, File_No, str(sequence), str(frame_num))\n",
    "                npy_path2 = os.path.join(npy_path, str(frame_num))\n",
    "                np.save(npy_path2, keypoints)\n",
    "        \n",
    "                \n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "#         Test = int(Test)\n",
    "#         Test += 1\n",
    "        print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d797bd",
   "metadata": {},
   "source": [
    "# Preprocess Data and Create Labels and Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3d0dbd4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Let_List = []\n",
    "wb = open_workbook(r'F:\\Signlanguage\\Jupyter\\DichNNKH\\VideoFileTranslatorList_3_checked_test_2words.xls')\n",
    "sheet = wb.sheet_by_index(0)\n",
    "sheet.cell_value(0, 0)\n",
    "column_index = 0\n",
    "column = sheet.cell_value(0, column_index)\n",
    "no_sequences = 30\n",
    "\n",
    "for row in range(3, sheet.nrows):\n",
    "    Let_Link = sheet.cell_value(row, column_index+5)\n",
    "    Let_List.append(Let_Link)\n",
    "Let_Arr = np.array(Let_List)\n",
    "\n",
    "label_map = {label: num for num, label in enumerate(Let_Arr)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5c5649d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['địa chỉ', 'Tỉnh', 'Tiếp Tân', 'nhân viên'], dtype='<U9')"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Let_Arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "72081f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This set of array is required to keep the Numpy array in shape\n",
    "\n",
    "Null_List = []\n",
    "Null_Arr = np.array(Null_List)\n",
    "\n",
    "for n in range(1662): \n",
    "    Null_Arr = np.append(Null_Arr, [0])\n",
    "    n+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c8d1ba49",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences, labels = [], []\n",
    "\n",
    "DATA_PATH = os.path.join('MP_Data')\n",
    "\n",
    "sheet = wb.sheet_by_index(0)\n",
    "sheet.cell_value(0, 0)\n",
    "column_index = 0\n",
    "column = sheet.cell_value(0, column_index)\n",
    "\n",
    "for row in range(3, sheet.nrows):\n",
    "    Vid_Link = sheet.cell_value(row, column_index+3)\n",
    "    Letter = sheet.cell_value(row, column_index+5)\n",
    "    File_No = str(sheet.cell_value(row, column_index))\n",
    "\n",
    "\n",
    "    for sequence in range(no_sequences):\n",
    "        cap = cv2.VideoCapture(Vid_Link)\n",
    "        window = []\n",
    "        Frame_length = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "        for frame_num in range(30):\n",
    "            try:\n",
    "                res = np.load(os.path.join(DATA_PATH, Letter, str(sequence), \"{}.npy\".format(frame_num)))\n",
    "                \n",
    "                #print(res)\n",
    "                #print(len(res))\n",
    "                window.append(res)\n",
    "                \n",
    "            except:\n",
    "                window.append(res)\n",
    "                \n",
    "        sequences.append(window)\n",
    "        labels.append(label_map[Letter])\n",
    "        #print(sequences,'1')\n",
    "        #print(labels, '2')\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d3007b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(sequences)\n",
    "y = to_categorical(labels).astype(int)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "13b737c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "399d224c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(114, 30, 1662)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "566a6c0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120, 30, 1662)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(sequences).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1c802709",
   "metadata": {},
   "outputs": [],
   "source": [
    "#res = np.array(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2221a0a7",
   "metadata": {},
   "source": [
    "# Build and Train LSTM Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "66e2d0cc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "log_dir = os.path.join('Logs')\n",
    "tb_callback = TensorBoard(log_dir=log_dir)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(64, return_sequences=True, activation='relu', input_shape=(30,1662)))\n",
    "model.add(LSTM(128, return_sequences=True, activation='relu'))\n",
    "model.add(LSTM(64, return_sequences=False, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(Let_Arr.shape[0], activation='softmax'))\n",
    "\n",
    "#res = [.7, 0.2, 0.1]\n",
    "\n",
    "opt = tf.keras.optimizers.SGD(learning_rate = 0.25)#learning_rate = 0.01\n",
    "\n",
    "model.compile(optimizer= 'Adam', loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "9eb58526",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['địa chỉ', 'Tỉnh', 'Tiếp Tân', 'nhân viên'], dtype='<U9')"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Let_Arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d493aa82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "4/4 [==============================] - 2s 85ms/step - loss: 1.5764 - categorical_accuracy: 0.2895\n",
      "Epoch 2/2000\n",
      "4/4 [==============================] - 1s 159ms/step - loss: 7.9959 - categorical_accuracy: 0.3070\n",
      "Epoch 3/2000\n",
      "4/4 [==============================] - 0s 89ms/step - loss: 1.4988 - categorical_accuracy: 0.2632\n",
      "Epoch 4/2000\n",
      "4/4 [==============================] - 0s 88ms/step - loss: 1.4079 - categorical_accuracy: 0.2632\n",
      "Epoch 5/2000\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 1.3458 - categorical_accuracy: 0.3070\n",
      "Epoch 6/2000\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 1.2797 - categorical_accuracy: 0.2368\n",
      "Epoch 7/2000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.0882 - categorical_accuracy: 0.4792"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [71]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mtb_callback\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py:1409\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1402\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1403\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   1404\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   1405\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[0;32m   1406\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m   1407\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m   1408\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1409\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1410\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1411\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateless_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2453\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2450\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   2451\u001b[0m   (graph_function,\n\u001b[0;32m   2452\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2453\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2454\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1860\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1856\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1857\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1858\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1859\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1860\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1861\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1862\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1863\u001b[0m     args,\n\u001b[0;32m   1864\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1865\u001b[0m     executing_eagerly)\n\u001b[0;32m   1866\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:497\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    495\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    496\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 497\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    503\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    504\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    505\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    506\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    509\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    510\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=2000, callbacks=[tb_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f0ef784f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_6 (LSTM)               (None, 30, 64)            442112    \n",
      "                                                                 \n",
      " lstm_7 (LSTM)               (None, 30, 128)           98816     \n",
      "                                                                 \n",
      " lstm_8 (LSTM)               (None, 64)                49408     \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 4)                 132       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 596,708\n",
      "Trainable params: 596,708\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2fe7b0ce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 250ms/step\n"
     ]
    }
   ],
   "source": [
    "res = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1263b57f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3af2ed67",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 1 is out of bounds for axis 0 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [29]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m Let_Arr[np\u001b[38;5;241m.\u001b[39margmax(\u001b[43mres\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m)]\n",
      "\u001b[1;31mIndexError\u001b[0m: index 1 is out of bounds for axis 0 with size 1"
     ]
    }
   ],
   "source": [
    "Let_Arr[np.argmax(res[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f11c99ef",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 1 is out of bounds for axis 0 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [30]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m Let_Arr[np\u001b[38;5;241m.\u001b[39margmax(\u001b[43my_test\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m)]\n",
      "\u001b[1;31mIndexError\u001b[0m: index 1 is out of bounds for axis 0 with size 1"
     ]
    }
   ],
   "source": [
    "Let_Arr[np.argmax(y_test[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8b0f3f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('action.h5') # Save weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8a4875b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('action.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3d61510b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 35ms/step\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import multilabel_confusion_matrix, accuracy_score\n",
    "\n",
    "yhat = model.predict(X_test)\n",
    "ytrue = np.argmax(y_test, axis=1).tolist()\n",
    "yhat = np.argmax(yhat, axis=1).tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3d0bd1d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0., 1.],\n",
       "        [0., 0.]],\n",
       "\n",
       "       [[0., 0.],\n",
       "        [1., 0.]]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multilabel_confusion_matrix(ytrue, yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b9ed2304",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(ytrue, yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a03eef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
